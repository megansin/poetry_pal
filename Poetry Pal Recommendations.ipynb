{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ics07\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense, Multiply\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'goodreads_interactions_poetry.json.gz'\n",
    "\n",
    "dataset = []\n",
    "\n",
    "with gzip.open(path, 'rt', encoding='utf8') as file:\n",
    "    # Process the file line by line\n",
    "    for line in file:\n",
    "        # Decode each line from JSON format\n",
    "        json_content = json.loads(line)\n",
    "        dataset.append(json_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'goodreads_books_poetry.json.gz'\n",
    "\n",
    "info = []\n",
    "\n",
    "with gzip.open(path, 'rt', encoding='utf8') as file:\n",
    "    # Process the file line by line\n",
    "    for line in file:\n",
    "        # Decode each line from JSON format\n",
    "        json_content = json.loads(line)\n",
    "        info.append(json_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookInfo = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in info:\n",
    "    book_id, title = i['book_id'], i['title']\n",
    "    bookInfo[book_id] = title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerItem = defaultdict(set)\n",
    "itemsPerUser = defaultdict(set)\n",
    "items = []\n",
    "users = []\n",
    "ratings = []\n",
    "ratingDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataset:\n",
    "    user,item, rating = d['user_id'], d['book_id'], d['rating']\n",
    "    usersPerItem[item].add(user)\n",
    "    itemsPerUser[user].add(item)\n",
    "    ratingDict[(user, item)] = rating\n",
    "    items.append(item)\n",
    "    users.append(user)\n",
    "    ratings.append(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueItems = list(set(items))\n",
    "uniqueUsers = list(set(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user and item indices\n",
    "user_index = {user: i for i, user in enumerate(uniqueUsers)}\n",
    "item_index = {item: i for i, item in enumerate(uniqueItems)}\n",
    "\n",
    "# Convert reviews to numerical data\n",
    "user_ids = [user_index[d['user_id']] for d in dataset]\n",
    "item_ids = [item_index[d['book_id']] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ncf_model_with_gmf(num_users, num_items, embedding_size=64, hidden_units=(64, 32)):\n",
    "    user_input = Input(shape=(1,), name='user_input')\n",
    "    item_input = Input(shape=(1,), name='item_input')\n",
    "\n",
    "    user_embedding = Embedding(input_dim=num_users, output_dim=embedding_size)(user_input)\n",
    "    item_embedding = Embedding(input_dim=num_items, output_dim=embedding_size)(item_input)\n",
    "\n",
    "    # GMF\n",
    "    gmf_layer = Multiply()([user_embedding, item_embedding])\n",
    "\n",
    "    user_flat = Flatten()(user_embedding)\n",
    "    item_flat = Flatten()(item_embedding)\n",
    "    gmf_flat = Flatten()(gmf_layer)\n",
    "\n",
    "    # MLP\n",
    "    mlp_output = Concatenate()([user_flat, item_flat])\n",
    "    for units in hidden_units:\n",
    "        mlp_output = Dense(units, activation='relu')(mlp_output)\n",
    "\n",
    "    # CONCAT\n",
    "    concat = Concatenate()([mlp_output, gmf_flat])\n",
    "\n",
    "    output = Dense(1, activation='relu')(concat)\n",
    "\n",
    "    model = Model(inputs=[user_input, item_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN AND EVAL\n",
    "user_ids = np.array(user_ids)\n",
    "item_ids = np.array(item_ids)\n",
    "ratings = np.array(ratings)\n",
    "\n",
    "ncf_model_with_gmf = create_ncf_model_with_gmf(len(user_ids), len(item_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "219/219 [==============================] - 303s 1s/step - loss: 3.6322 - mae: 1.4468 - val_loss: 4.4399 - val_mae: 1.8823\n",
      "Epoch 2/5\n",
      "219/219 [==============================] - 280s 1s/step - loss: 2.4367 - mae: 1.1571 - val_loss: 4.4122 - val_mae: 1.8788\n",
      "Epoch 3/5\n",
      "219/219 [==============================] - 278s 1s/step - loss: 2.2926 - mae: 1.0968 - val_loss: 4.4191 - val_mae: 1.8711\n",
      "Epoch 4/5\n",
      "219/219 [==============================] - 279s 1s/step - loss: 2.1881 - mae: 1.0497 - val_loss: 4.4675 - val_mae: 1.8599\n",
      "Epoch 5/5\n",
      "219/219 [==============================] - 279s 1s/step - loss: 2.0677 - mae: 0.9994 - val_loss: 4.4928 - val_mae: 1.8634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f8db848b50>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncf_model_with_gmf.fit([user_ids, item_ids], ratings, epochs=5, batch_size=10000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncf_model_with_gmf.save(\"leaky relu neumf.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncf_model_with_gmf = tf.keras.models.load_model('neumf.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cold_start(top_n = 10):\n",
    "    recs = []\n",
    "\n",
    "    itemsToPredict = []\n",
    "    usersToPredict = []\n",
    "\n",
    "    for i in range(len(uniqueItems)):\n",
    "        itemsToPredict.append(i)\n",
    "\n",
    "    for i in itemsToPredict:\n",
    "        usersToPredict.append(500000)\n",
    "\n",
    "    itemsToPredict = np.array(itemsToPredict)\n",
    "    usersToPredict = np.array(usersToPredict)\n",
    "    prediction = ncf_model_with_gmf.predict([usersToPredict, itemsToPredict])\n",
    "    \n",
    "    for i in range(len(prediction)):\n",
    "        recs.append((uniqueItems[itemsToPredict[i]], prediction[i]))\n",
    "    recs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(f\"Top {top_n} Recommendations for User\")\n",
    "    for i, (recommended_item, predicted_rating) in enumerate(recs[:top_n]):\n",
    "        print(f\"{i + 1}. Book: {bookInfo[recommended_item]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_recommendations(user, top_n=10):\n",
    "\n",
    "    recs = []\n",
    "    knownItems = itemsPerUser[user]\n",
    "    \n",
    "    user_id = user_index[user]\n",
    "    itemsToPredict = []\n",
    "    usersToPredict = []\n",
    "\n",
    "    for i in range(len(uniqueItems)):\n",
    "        if uniqueItems[i] not in knownItems:\n",
    "            itemsToPredict.append(i)\n",
    "\n",
    "    for i in itemsToPredict:\n",
    "        usersToPredict.append(user_id)\n",
    "\n",
    "    itemsToPredict = np.array(itemsToPredict)\n",
    "    usersToPredict = np.array(usersToPredict)\n",
    "    prediction = ncf_model_with_gmf.predict([usersToPredict, itemsToPredict])\n",
    "    \n",
    "    for i in range(len(prediction)):\n",
    "        recs.append((uniqueItems[itemsToPredict[i]], prediction[i]))\n",
    "    recs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"User's has\", len(knownItems),\"ratings.\")\n",
    "\n",
    "    if (len(knownItems) > 5):\n",
    "        print(\"Here are five of them:\")\n",
    "        sampleItems = list(knownItems)[0:5]\n",
    "        for i in sampleItems:\n",
    "            print(f\"{bookInfo[i]}: {ratingDict[(user, i)]}\")\n",
    "    else:\n",
    "        for i in knownItems:\n",
    "            print(f\"Book: {bookInfo[i]}, Rating: {ratingDict[(user, i)]}\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(f\"Top {top_n} Recommendations for User\")\n",
    "    for i, (recommended_item, predicted_rating) in enumerate(recs[:top_n]):\n",
    "        print(f\"{i + 1}. Book: {bookInfo[recommended_item]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1141/1141 [==============================] - 2s 2ms/step\n",
      "User's has 3 ratings.\n",
      "Book: The Iliad, Rating: 4\n",
      "Book: Where the Sidewalk Ends, Rating: 5\n",
      "Book: The Odyssey, Rating: 4\n",
      "\n",
      "\n",
      "Top 10 Recommendations for User\n",
      "1. Book: The Ashgate Research Companion to Thomas Hardy\n",
      "2. Book: Catmas Carols, revised edition\n",
      "3. Book: Een vijver vol inkt\n",
      "4. Book: The Short Fiction of Edgar Allan Poe\n",
      "5. Book: Sonety / The Sonnets\n",
      "6. Book: La Vida Es Sueño\n",
      "7. Book: The Man From Snowy River\n",
      "8. Book: My Planet of Kites\n",
      "9. Book: No te des por vencido\n",
      "10. Book: خذني إلى المسجد الأقصى\n"
     ]
    }
   ],
   "source": [
    "display_recommendations('8842281e1d1347389f2ab93d60773d4d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1142/1142 [==============================] - 2s 2ms/step\n",
      "Top 10 Recommendations for User\n",
      "1. Book: Stripped: A Collection of Inspired Writings for the Evolving Woman\n",
      "2. Book: Haiku for the Single Girl\n",
      "3. Book: The Canti: With a Selection of His Prose\n",
      "4. Book: The Ashgate Research Companion to Thomas Hardy\n",
      "5. Book: KarnaKavita\n",
      "6. Book: Black Movie\n",
      "7. Book: My Life By Water: Collected Poems, 1936 1968\n",
      "8. Book: Money Poems\n",
      "9. Book: Acorn\n",
      "10. Book: The Poetical Works of Thomas Lovell Beddoes\n"
     ]
    }
   ],
   "source": [
    "cold_start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1141/1141 [==============================] - 2s 2ms/step\n",
      "User's has 20 ratings.\n",
      "Here are five of them:\n",
      "Sand and Foam: 5\n",
      "The Book of Questions: 5\n",
      "Odes to Common Things: 3\n",
      "Leaves of Grass: 4\n",
      "The Selected Poems: 5\n",
      "\n",
      "\n",
      "Top 10 Recommendations for User\n",
      "1. Book: The Ashgate Research Companion to Thomas Hardy\n",
      "2. Book: The Collected Poetry, 1968-1998\n",
      "3. Book: Orchards: A Sequence of French Poems\n",
      "4. Book: المختار من شعر أبو القاسم الشابي\n",
      "5. Book: Just Around the Corner: Poems\n",
      "6. Book: Of Snails and Skylarks\n",
      "7. Book: Poesia de Ricardo Reis Obra Essencial de Fernando Pessoa, #5)\n",
      "8. Book: La Légende des Siècles\n",
      "9. Book: El hacedor\n",
      "10. Book: ملحمة كلكامش\n"
     ]
    }
   ],
   "source": [
    "display_recommendations('0d9674945bb29a45b5473e67c5b7208c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_rl = tf.keras.models.load_model('leaky relu neumf.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_recommendations(user, top_n=5):\n",
    "\n",
    "    recs = []\n",
    "    knownItems = itemsPerUser[user]\n",
    "    \n",
    "    user_id = user_index[user]\n",
    "    itemsToPredict = []\n",
    "    usersToPredict = []\n",
    "\n",
    "    for i in range(len(uniqueItems)):\n",
    "        if uniqueItems[i] in knownItems:\n",
    "            continue\n",
    "        itemsToPredict.append(i)\n",
    "\n",
    "    for i in itemsToPredict:\n",
    "        usersToPredict.append(user_id)\n",
    "\n",
    "    itemsToPredict = np.array(itemsToPredict)\n",
    "    usersToPredict = np.array(usersToPredict)\n",
    "    prediction = leaky_rl.predict([usersToPredict, itemsToPredict])\n",
    "    \n",
    "    for i in range(len(prediction)):\n",
    "        recs.append((uniqueItems[itemsToPredict[i]], prediction[i]))\n",
    "    recs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"User's current ratings:\")\n",
    "\n",
    "    for i in knownItems:\n",
    "        print(f\"Book: {bookInfo[i]}, Rating: {ratingDict[(user, i)]}\")\n",
    "        \n",
    "    print(f\"Top {top_n} Recommendations for User\")\n",
    "    for i, (recommended_item, predicted_rating) in enumerate(recs[:top_n]):\n",
    "        print(f\"{i + 1}. Book: {bookInfo[recommended_item]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1141/1141 [==============================] - 2s 2ms/step\n",
      "User's current ratings:\n",
      "Book: The Iliad, Rating: 4\n",
      "Book: Where the Sidewalk Ends, Rating: 5\n",
      "Book: The Odyssey, Rating: 4\n",
      "Top 5 Recommendations for User\n",
      "1. Book: Free Verse\n",
      "2. Book: Pole Dancing to Gospel Hymns\n",
      "3. Book: Uitzicht met zandkorrel\n",
      "4. Book: Þungi eyjunnar\n",
      "5. Book: ප්‍රබුද්ධ\n"
     ]
    }
   ],
   "source": [
    "leaky_recommendations('8842281e1d1347389f2ab93d60773d4d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
